{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw,y_raw = mnist.train.next_batch(40)\n",
    "# Constants and variables\n",
    "n_classes = 10\n",
    "img_width = 28\n",
    "img_height = 28\n",
    "\n",
    "# For ipython\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    \n",
    "     # Network\n",
    "        x = tf.placeholder(\"float\", [None, img_width*img_height])\n",
    "        y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "        xi = tf.reshape(x,[-1,28,28,1])\n",
    "        \n",
    "       \n",
    "        with tf.variable_scope(\"conv1\") as scope:\n",
    "                W = tf.get_variable(\"W\",shape=[3,3,1,32],initializer=tf.contrib.layers.xavier_initializer())\n",
    "                b = tf.get_variable(\"b\",initializer=tf.zeros([32]))\n",
    "                l1 = tf.nn.conv2d(xi,W,strides=[1,1,1,1],padding=\"VALID\")\n",
    "                l1_b = tf.nn.bias_add(l1,b)\n",
    "                l1_act = tf.nn.relu(l1_b)\n",
    "\n",
    "        with tf.variable_scope(\"conv2\") as scope:\n",
    "                W = tf.get_variable(\"W\",shape=[3,3,32,64],initializer=tf.contrib.layers.xavier_initializer())\n",
    "                b = tf.get_variable(\"b\",initializer=tf.zeros([64]))\n",
    "                l2 = tf.nn.conv2d(l1_act,W,strides=[1,1,1,1],padding=\"VALID\")\n",
    "                l2_b = tf.nn.bias_add(l2,b)\n",
    "                l2_act = tf.nn.relu(l2_b)\n",
    "\n",
    "        # Maxpooling\n",
    "        l3_max = tf.nn.max_pool(l2_act,[1,2,2,1],strides=[1,2,2,1],padding=\"VALID\")\n",
    "        \n",
    "        with tf.variable_scope(\"dense1\") as scope:\n",
    "                W = tf.get_variable(\"W\",shape=[12*12*64,128],initializer=tf.contrib.layers.xavier_initializer())\n",
    "                b = tf.get_variable(\"b\",initializer=tf.zeros([128]))\n",
    "                l4 = tf.reshape(l3_max,[-1,12*12*64])\n",
    "                l4 = tf.matmul(l4,W)\n",
    "                l4_b = tf.nn.bias_add(l4,b)\n",
    "                l4_act = tf.nn.relu(l4_b)\n",
    "\n",
    "\n",
    "        with tf.variable_scope(\"dense2\") as scope:\n",
    "                W = tf.get_variable(\"W\",shape=[128,n_classes],initializer=tf.contrib.layers.xavier_initializer())\n",
    "                b = tf.get_variable(\"b\",initializer=tf.zeros([n_classes]))\n",
    "                l5 = tf.matmul(l4,W)+b\n",
    "                \n",
    "                \n",
    "        eval_pred = tf.nn.softmax(l5)\n",
    "        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=l5,labels=y))\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "        return (x,y),train_step,cost,eval_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVar(name):\n",
    "        var = [v for v in tf.trainable_variables() if v.name==name+\":0\"][0]\n",
    "        return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y),train_step,cost,eval_pred = getModel()\n",
    "\n",
    "epochs = 1\n",
    "b_size = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0\n",
      "Epoch: 0, Iteration: 10\n",
      "Epoch: 0, Iteration: 20\n",
      "Epoch: 0, Iteration: 30\n",
      "Epoch: 0, Iteration: 40\n",
      "Epoch: 0, Iteration: 50\n",
      "Epoch: 0, Iteration: 60\n",
      "Epoch: 0, Iteration: 70\n",
      "Epoch: 0, Iteration: 80\n",
      "Epoch: 0, Iteration: 90\n",
      "Epoch: 0, Iteration: 100\n",
      "Epoch: 0, Iteration: 110\n",
      "Epoch: 0, Iteration: 120\n",
      "Epoch: 0, Iteration: 130\n",
      "Epoch: 0, Iteration: 140\n",
      "Epoch: 0, Iteration: 150\n",
      "Epoch: 0, Iteration: 160\n",
      "Epoch: 0, Iteration: 170\n",
      "Epoch: 0, Iteration: 180\n",
      "Epoch: 0, Iteration: 190\n",
      "Epoch: 0, Iteration: 200\n",
      "Epoch: 0, Iteration: 210\n",
      "Epoch: 0, Iteration: 220\n",
      "Epoch: 0, Iteration: 230\n",
      "Epoch: 0, Iteration: 240\n",
      "Epoch: 0, Iteration: 250\n",
      "Epoch: 0, Iteration: 260\n",
      "Epoch: 0, Iteration: 270\n",
      "Epoch: 0, Iteration: 280\n",
      "Epoch: 0, Iteration: 290\n",
      "Epoch: 0, Iteration: 300\n",
      "Epoch: 0, Iteration: 310\n",
      "Epoch: 0, Iteration: 320\n",
      "Epoch: 0, Iteration: 330\n",
      "Epoch: 0, Iteration: 340\n",
      "Epoch: 0, Iteration: 350\n",
      "Epoch: 0, Iteration: 360\n",
      "Epoch: 0, Iteration: 370\n",
      "Epoch: 0, Iteration: 380\n",
      "Epoch: 0, Iteration: 390\n",
      "Epoch: 0, Iteration: 400\n",
      "Epoch: 0, Iteration: 410\n",
      "Epoch: 0, Iteration: 420\n",
      "Epoch: 0, Iteration: 430\n",
      "Epoch: 0, Iteration: 440\n",
      "Epoch: 0, Iteration: 450\n",
      "Epoch: 0, Iteration: 460\n",
      "Epoch: 0, Iteration: 470\n",
      "Epoch: 0, Iteration: 480\n",
      "Epoch: 0, Iteration: 490\n",
      "Epoch: 0, Iteration: 500\n",
      "Epoch: 0, Iteration: 510\n",
      "Epoch: 0, Iteration: 520\n",
      "Epoch: 0, Iteration: 530\n",
      "Epoch: 0, Iteration: 540\n",
      "Epoch: 0, Iteration: 550\n",
      "Epoch: 0, Iteration: 560\n",
      "Epoch: 0, Iteration: 570\n",
      "Epoch: 0, Iteration: 580\n",
      "Epoch: 0, Iteration: 590\n",
      "Epoch: 0, Iteration: 600\n",
      "Epoch: 0, Iteration: 610\n",
      "Epoch: 0, Iteration: 620\n",
      "Epoch: 0, Iteration: 630\n",
      "Epoch: 0, Iteration: 640\n",
      "Epoch: 0, Iteration: 650\n",
      "Epoch: 0, Iteration: 660\n",
      "Epoch: 0, Iteration: 670\n",
      "Epoch: 0, Iteration: 680\n",
      "Epoch: 0, Iteration: 690\n",
      "Epoch: 0, Iteration: 700\n",
      "Epoch: 0, Iteration: 710\n",
      "Epoch: 0, Iteration: 720\n",
      "Epoch: 0, Iteration: 730\n",
      "Epoch: 0, Iteration: 740\n",
      "Epoch: 0, Iteration: 750\n",
      "Epoch: 0, Iteration: 760\n",
      "Epoch: 0, Iteration: 770\n",
      "Epoch: 0, Iteration: 780\n",
      "Epoch: 0, Iteration: 790\n",
      "Epoch: 0, Iteration: 800\n",
      "Epoch: 0, Iteration: 810\n",
      "Epoch: 0, Iteration: 820\n",
      "Epoch: 0, Iteration: 830\n",
      "Epoch: 0, Iteration: 840\n",
      "Epoch: 0, Iteration: 850\n",
      "Epoch: 0, Iteration: 860\n",
      "Epoch: 0, Iteration: 870\n",
      "Epoch: 0, Iteration: 880\n",
      "Epoch: 0, Iteration: 890\n",
      "Epoch: 0, Iteration: 900\n",
      "Epoch: 0, Iteration: 910\n",
      "Epoch: 0, Iteration: 920\n",
      "Epoch: 0, Iteration: 930\n",
      "Epoch: 0, Iteration: 940\n",
      "Epoch: 0, Iteration: 950\n",
      "Epoch: 0, Iteration: 960\n",
      "Epoch: 0, Iteration: 970\n",
      "Epoch: 0, Iteration: 980\n",
      "Epoch: 0, Iteration: 990\n",
      "0.762\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "        # Training\n",
    "        for i in range(epochs):\n",
    "                for j in range(0,1000,b_size):\n",
    "                        print(\"Epoch: {0}, Iteration: {1}\".format(i,j))\n",
    "                        x_raw = mnist.train.images[j:j+b_size]\n",
    "                        y_raw = mnist.train.labels[j:j+b_size]\n",
    "\n",
    "                        [_,c]=sess.run([train_step,cost],feed_dict={x:x_raw,y:y_raw})\n",
    "\n",
    "        k = getVar(\"dense1/b\").eval()\n",
    "\n",
    "        # Testing\n",
    "        gc=0;tc=0;\n",
    "        for i in range(1000):\n",
    "                x_raw = mnist.test.images[i:i+1]\n",
    "                y_raw = mnist.test.labels[i:i+1]\n",
    "\n",
    "                pred = sess.run(eval_pred,feed_dict={x:x_raw})\n",
    "\n",
    "                if np.argmax(pred)==np.argmax(y_raw):\n",
    "                        gc+=1\n",
    "                tc+=1\n",
    "\n",
    "        print(1.0*gc/tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
